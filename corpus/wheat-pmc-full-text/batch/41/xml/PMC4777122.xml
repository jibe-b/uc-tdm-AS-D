<?xml version="1.0"?>
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article">
  <?properties open_access?>
  <?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Publishing DTD v2.3 20070202//EN?>
  <?DTDIdentifier.IdentifierType public?>
  <?SourceDTD.DTDName journalpublishing.dtd?>
  <?SourceDTD.Version 2.3?>
  <?ConverterInfo.XSLTName jp2nlmx2.xsl?>
  <?ConverterInfo.Version 2?>
  <front>
    <journal-meta>
      <journal-id journal-id-type="nlm-ta">G3 (Bethesda)</journal-id>
      <journal-id journal-id-type="iso-abbrev">Genetics</journal-id>
      <journal-id journal-id-type="hwp">G3: Genes, Genomes, Genetics</journal-id>
      <journal-id journal-id-type="pmc">G3: Genes, Genomes, Genetics</journal-id>
      <journal-id journal-id-type="publisher-id">G3: Genes, Genomes, Genetics</journal-id>
      <journal-title-group>
        <journal-title>G3: Genes|Genomes|Genetics</journal-title>
      </journal-title-group>
      <issn pub-type="epub">2160-1836</issn>
      <publisher>
        <publisher-name>Genetics Society of America</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="pmcid">4777122</article-id>
      <article-id pub-id-type="pmid">26715095</article-id>
      <article-id pub-id-type="publisher-id">GGG_026328</article-id>
      <article-id pub-id-type="doi">10.1534/g3.115.026328</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Genomic Selection</subject>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>FW: An R Package for Finlay&#x2013;Wilkinson Regression that Incorporates Genomic/Pedigree Information and Covariance Structures Between Environments</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Lian</surname>
            <given-names>Lian</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">*</xref>
          <xref ref-type="corresp" rid="cor1">
            <sup>1</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>de los Campos</surname>
            <given-names>Gustavo</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">*</xref>
          <xref ref-type="aff" rid="aff2">
            <sup>&#x2020;</sup>
          </xref>
        </contrib>
        <aff id="aff1"><label>*</label>Department of Epidemiology and Biostatistics, Michigan State University, East Lansing, Michigan 48824</aff>
        <aff id="aff2"><label>&#x2020;</label>Department of Probability and Statistics, Michigan State University, East Lansing, Michigan 48824</aff>
      </contrib-group>
      <author-notes>
        <corresp id="cor1"><label>1</label>Corresponding author: Department of Epidemiology and Biostatistics, Michigan State University, 909 Fee Road, Room B601, East Lansing, MI 48824. E-mail: <email>lianl0501@gmail.com</email></corresp>
      </author-notes>
      <pub-date pub-type="epub">
        <day>29</day>
        <month>12</month>
        <year>2015</year>
      </pub-date>
      <pub-date pub-type="collection">
        <month>3</month>
        <year>2016</year>
      </pub-date>
      <volume>6</volume>
      <issue>3</issue>
      <fpage>589</fpage>
      <lpage>597</lpage>
      <history>
        <date date-type="received">
          <day>29</day>
          <month>10</month>
          <year>2015</year>
        </date>
        <date date-type="accepted">
          <day>23</day>
          <month>12</month>
          <year>2015</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>Copyright &#xA9; 2016 Lian and Campos</copyright-statement>
        <copyright-year>2016</copyright-year>
        <license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/4.0/">
          <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution 4.0 International License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p>
        </license>
      </permissions>
      <self-uri xlink:title="pdf" xlink:type="simple" xlink:href="589.pdf"/>
      <abstract>
        <p>The Finlay&#x2013;Wilkinson regression (FW) is a popular method among plant breeders to describe genotype by environment interaction. The standard implementation is a two-step procedure that uses environment (sample) means as covariates in a within-line ordinary least squares (OLS) regression. This procedure can be suboptimal for at least four reasons: (1) in the first step environmental means are typically estimated without considering genetic-by-environment interactions, (2) in the second step uncertainty about the environmental means is ignored, (3) estimation is performed regarding lines and environment as fixed effects, and (4) the procedure does not incorporate genetic (either pedigree-derived or marker-derived) relationships. Su <italic>et al.</italic> proposed to address these problems using a Bayesian method that allows simultaneous estimation of environmental and genotype parameters, and allows incorporation of pedigree information. In this article we: (1) extend the model presented by Su <italic>et al.</italic> to allow integration of genomic information [<italic>e.g.</italic>, single nucleotide polymorphism (SNP)] and covariance between environments, (2) present an R package (FW) that implements these methods, and (3) illustrate the use of the package using examples based on real data. The FW R package implements both the two-step OLS method and a full Bayesian approach for Finlay&#x2013;Wilkinson regression with a very simple interface. Using a real wheat data set we demonstrate that the prediction accuracy of the Bayesian approach is consistently higher than the one achieved by the two-step OLS method.</p>
      </abstract>
      <kwd-group>
        <kwd>Bayesian</kwd>
        <kwd>Finlay&#x2013;Wilkinson</kwd>
        <kwd>genomic/environment</kwd>
        <kwd>correlation</kwd>
        <kwd>genotype by environment interaction</kwd>
        <kwd>reaction norm</kwd>
        <kwd>GenPred</kwd>
        <kwd>genomic selection</kwd>
        <kwd>shared data resource</kwd>
      </kwd-group>
      <counts>
        <fig-count count="5"/>
        <table-count count="14"/>
        <equation-count count="4"/>
        <ref-count count="15"/>
        <page-count count="9"/>
      </counts>
    </article-meta>
  </front>
  <body>
    <p>Plant breeders use the Finlay&#x2013;Wilkinson regression (<xref rid="bib4" ref-type="bibr">Finlay and Wilkinson 1963</xref>) to assess stability of varieties across different environments. The FW aims at assessing how the expected performance of a genotype varies as a function of the environmental effects. Usually this is achieved by regressing the performance of each genotype on the environmental means. Compared with a completely unstructured genotype by environment interaction (G &#xD7; E) model that fits every level of genotype and environment combination, the Finlay&#x2013;Wilkinson regression is parsimonious and can reveal a trend of variety performance across environments. Breeders can use this model to select for plants either based on stability or on responsiveness to environment potential (<xref rid="bib15" ref-type="bibr">Walsh and Lynch 2014</xref>).</p>
    <p>The standard implementation of Finlay&#x2013;Wilkinson regression is a two-step procedure whereas in the first step environmental sample means are computed and in the second step intercepts and slopes of each line are estimated by regressing, within line, the performance of each line on the estimated environmental means. This procedure has at least four potential limitations: (1) in the first step environmental means are typically estimated without considering G &#xD7; E; (2) in the second step, uncertainty about the environmental means is ignored; (3) the environmental means and the variety intercepts and slopes are regarded as fixed effects (this can lead to large sampling variance of estimates); and (4) the procedure does not offer a clear way of incorporating pedigree or molecular marker information when estimating the intercepts and slopes of the lines. These drawbacks can induce biases (especially in incomplete designs where a few lines are evaluated in each environment) and lead to large sampling variance of estimates.</p>
    <p><xref rid="bib14" ref-type="bibr">Su <italic>et al.</italic> (2006)</xref> proposed a Bayesian method that addresses the limitations of the standard two-step procedure. The methodology described by Su <italic>et al.</italic>: (1) uses a Gibbs sampler that allows estimating environmental and genotype parameters jointly; (2) fully accounts for confounding and uncertainty about environmental means; (3) treats environmental means and the intercepts and slopes of the lines as random &#x2013; this treatment usually performs better than ordinary least squares in terms of mean-squared error and of prediction accuracy, especially when the number of parameters to be estimated is large relative to sample size (<xref rid="bib2" ref-type="bibr">Copas 1983</xref>; <xref rid="bib5" ref-type="bibr">Frank and Friedman 1993</xref>); and (4) allows incorporating pedigree information into the model. Using simulations, <xref rid="bib14" ref-type="bibr">Su <italic>et al.</italic> (2006)</xref> reported better statistical performance of the Bayesian method for estimating model parameters. In this article we extend the model proposed by <xref rid="bib14" ref-type="bibr">Su <italic>et al.</italic> (2006)</xref> in ways that allow incorporating genomic [<italic>e.g.</italic>, single nucleotide polymorphism (SNP)] information and covariance between the environment effects.</p>
    <p>To the best of our knowledge the methodology described by Su <italic>et al.</italic> for animal breeding applications has not been considered in plant breeding, and there is no publicly available user-friendly software for implementing a Bayesian Finlay-Wilkinson regression. Therefore, in this article we introduce an R package (<xref rid="bib12" ref-type="bibr">R Development Core Team 2011</xref>) that implements the Finlay&#x2013;Wilkinson regression. The FW package implements both the two-step ordinary least squares (OLS) procedure and Bayesian single step procedure that allows incorporating covariance structure for varieties (<italic>e.g.</italic>, a pedigree or marker-derived kinship matrix) and environments. We describe the methods implemented in the package and show with examples how this package can be used to perform the Finlay&#x2013;Wilkinson regression with both methods. Finally, we present an evaluation of prediction accuracy for the Bayesian and two-step OLS methods with a wheat data set.</p>
    <sec id="s1">
      <title>Model Specification and Algorithm</title>
      <p>In a reaction norm model (<xref rid="bib7" ref-type="bibr">Gregorius and Namkoong 1986</xref>; <xref rid="bib10" ref-type="bibr">Perkins and Jinks 1968</xref>) the phenotypic record of the <italic>k</italic><sup>th</sup> replicate of the <italic>i</italic><sup>th</sup> variety observed in the <italic>j</italic><sup>th</sup> environment is modeled as follows:<disp-formula id="eq1"><mml:math id="me4"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>&#x3BC;</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>h</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>&#x3B5;</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math><label>[Equation 1]</label></disp-formula>where <inline-formula><mml:math id="me5"><mml:mrow><mml:msub><mml:mi>g</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is the main effect of <italic>i</italic><sup>th</sup> variety and <inline-formula><mml:math id="me7"><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> is the main effect of the <italic>j</italic><sup>th</sup> environment, and <inline-formula><mml:math id="me9"><mml:mrow><mml:msub><mml:mi>&#x3B5;</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is an error term, usually assumed to be IID normal with mean zero and variance <inline-formula><mml:math id="me10"><mml:mrow><mml:msubsup><mml:mi>&#x3C3;</mml:mi><mml:mi>&#x3B5;</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>. When we reorganize Equation 1 into the form: <inline-formula><mml:math id="me11"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>&#x3BC;</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>&#x3B5;</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>, we can recognize that <inline-formula><mml:math id="me12"><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>&#xA0;</mml:mo></mml:mrow></mml:math></inline-formula>is the change of expected variety performance per unit change of the environment effect (<inline-formula><mml:math id="me13"><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>). If there are no replicates the index <italic>k</italic> can be removed. With this, the equation reduces to <inline-formula><mml:math id="me14"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>&#x3BC;</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>h</mml:mi><mml:mrow><mml:mi>j</mml:mi><mml:mo>&#xA0;</mml:mo></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>&#x3B5;</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula>. The collection of parameters to be estimated from the model of Equation 1 includes the intercept and the vectors of effects: <inline-formula><mml:math id="me15"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>g</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mtext>g</mml:mtext><mml:mtext>i</mml:mtext></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="me16"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>b</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mtext>b</mml:mtext><mml:mtext>i</mml:mtext></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="me17"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>h</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:msub><mml:mtext>h</mml:mtext><mml:mtext>j</mml:mtext></mml:msub><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>.</p>
      <sec id="s2">
        <title>Estimation using two-steps methods</title>
        <p>The Finlay&#x2013;Wilkinson regression requires regressing the observed phenotypes of the line on environment effects. In the standard Finlay&#x2013;Wilkinson regression (<xref rid="bib4" ref-type="bibr">Finlay and Wilkinson 1963</xref>) the environmental effects are computed from the sample environmental means. However, in incomplete designs the sample mean of an environment may not be an unbiased estimate of the true environment mean. Therefore, a better estimate of environment effects comes from a regression that accounts for both environment effects and genotype effects, that is:<list list-type="simple" id="L1"><list-item><p>&#x2003;<bold>Step 1</bold>&#x2013; estimate the environmental effect using a main effects model:<disp-formula id="eq2"><mml:math id="me18"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>&#x3BC;</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>&#x3B5;</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math><label>[Equation 2]</label></disp-formula></p></list-item></list>The above regression yields estimates of environment effects (<inline-formula><mml:math id="me19"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>); these can be used in the second step to estimate the intercepts and slopes of each line.<list list-type="simple" id="L2"><list-item><p>&#x2003;<bold>Step 2</bold>&#x2013; replace <inline-formula><mml:math id="me20"><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> with <inline-formula><mml:math id="me21"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> in Equation 1 yielding:<disp-formula id="eq3"><mml:math id="me22"><mml:mrow><mml:msub><mml:mi>y</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>&#x3BC;</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mtext>i</mml:mtext></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>&#x3B5;</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math><label>[Equation 3]</label></disp-formula></p></list-item></list>Both Equation 2 and Equation 3 can be implemented with either OLS or mixed models. The current FW package implemented both Step 1 and Step 2 with OLS. In Step 1, Equation 2 is fitted with the constraint that <inline-formula><mml:math id="me23"><mml:mrow><mml:munder><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>&#x2211;</mml:mo></mml:mstyle><mml:mi>j</mml:mi></mml:munder><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="me24"><mml:mrow><mml:munder><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>&#x2211;</mml:mo></mml:mstyle><mml:mi>i</mml:mi></mml:munder><mml:msub><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>. Step 2 is implemented by fitting Equation 3 separately within each line with the constraint <inline-formula><mml:math id="me25"><mml:mrow><mml:mover accent="true"><mml:mi>&#x3BC;</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>.</p>
      </sec>
      <sec id="s3">
        <title>Bayesian approach</title>
        <p>Bayesian inferences are based on the posterior distribution of unknown parameters given the data: <inline-formula><mml:math id="me26"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>&#x3B8;</mml:mi></mml:mstyle><mml:mtext>|</mml:mtext><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x221D;</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle><mml:mo>|</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>&#x3B8;</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>&#x3B8;</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, where <bold><italic>&#x3B8;</italic></bold> represents the collection of the unknowns: <inline-formula><mml:math id="me28"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>&#x3B8;</mml:mi></mml:mstyle><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mi>&#x3BC;</mml:mi></mml:mrow></mml:math></inline-formula>, <bold><italic>g</italic></bold>, <bold><italic>b</italic></bold>, <bold><italic>h</italic></bold>, <inline-formula><mml:math id="me32"><mml:mrow><mml:msubsup><mml:mi>&#x3C3;</mml:mi><mml:mi>g</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="me33"><mml:mrow><mml:msubsup><mml:mi>&#x3C3;</mml:mi><mml:mi>b</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="me34"><mml:mrow><mml:msubsup><mml:mi>&#x3C3;</mml:mi><mml:mi>h</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="me35"><mml:mrow><mml:msubsup><mml:mi>&#x3C3;</mml:mi><mml:mi>&#x3B5;</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="me36"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle><mml:mo>|</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>&#x3B8;</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is the conditional distribution of the data given the parameters, and <inline-formula><mml:math id="me37"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>&#x3B8;</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is the joint prior distribution assigned to the model unknowns. According to Equation 1 and assuming IID normal residuals, we have:<disp-formula id="eq"><mml:math id="me38"><mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>y</mml:mi></mml:mstyle><mml:mo>|</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>&#x3B8;</mml:mi></mml:mstyle><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:munder><mml:mstyle mathsize="140%" displaystyle="true"><mml:mo>&#x220F;</mml:mo></mml:mstyle><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:munder><mml:mtext>N</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mi>&#x3BC;</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>h</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mi>&#x3C3;</mml:mi><mml:mi>&#x3B5;</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math>.</disp-formula>In the FW package, the prior density is assumed to have the following form: <inline-formula><mml:math id="me39"><mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>&#x3B8;</mml:mi></mml:mstyle><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:msubsup><mml:mi>&#x3C3;</mml:mi><mml:mi>&#x3B5;</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>g</mml:mi></mml:mstyle><mml:mo>|</mml:mo><mml:msubsup><mml:mi>&#x3C3;</mml:mi><mml:mi>g</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>b</mml:mi></mml:mstyle><mml:mo>|</mml:mo><mml:msubsup><mml:mi>&#x3C3;</mml:mi><mml:mi>b</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>h</mml:mi></mml:mstyle><mml:mo>|</mml:mo><mml:msubsup><mml:mi>&#x3C3;</mml:mi><mml:mi>h</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>&#x3C3;</mml:mi><mml:mi>g</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>&#x3C3;</mml:mi><mml:mi>b</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">)</mml:mo><mml:mi>p</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msubsup><mml:mi>&#x3C3;</mml:mi><mml:mi>h</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>. The residual variance <inline-formula><mml:math id="me40"><mml:mrow><mml:msubsup><mml:mi>&#x3C3;</mml:mi><mml:mi>&#x3B5;</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> is assigned a scaled-inverse <inline-formula><mml:math id="me41"><mml:mrow><mml:msup><mml:mi>&#x3C7;</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula> distribution: <inline-formula><mml:math id="me42"><mml:mrow><mml:msubsup><mml:mi>&#x3C3;</mml:mi><mml:mi>&#x3B5;</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo>&#x223C;</mml:mo><mml:msup><mml:mi>&#x3C7;</mml:mi><mml:mrow><mml:mo>&#x2212;</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>&#x3BD;</mml:mi><mml:mi>&#x3B5;</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msubsup><mml:mi>S</mml:mi><mml:mi>&#x3B5;</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, with degrees of freedom <inline-formula><mml:math id="me43"><mml:mrow><mml:msub><mml:mi>&#x3BD;</mml:mi><mml:mi>&#x3B5;</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> (&gt;0) and scale parameter <inline-formula><mml:math id="me44"><mml:mrow><mml:msubsup><mml:mi>S</mml:mi><mml:mi>&#x3B5;</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> (&gt;0), in the parameterization used <inline-formula><mml:math id="me45"><mml:mrow><mml:mi>E</mml:mi><mml:mo stretchy="false">[</mml:mo><mml:msubsup><mml:mi>&#x3C3;</mml:mi><mml:mi>&#x3B5;</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">]</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>&#x3BD;</mml:mi><mml:mi>&#x3B5;</mml:mi></mml:msub><mml:msubsup><mml:mi>S</mml:mi><mml:mi>&#x3B5;</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow><mml:mrow><mml:msub><mml:mi>&#x3BD;</mml:mi><mml:mi>&#x3B5;</mml:mi></mml:msub><mml:mo>&#x2212;</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula>. The overall mean <italic>&#x3BC;</italic> is assigned a flat prior. The prior distributions for <bold><italic>g</italic></bold>, <bold><italic>b</italic></bold>, and <bold><italic>h</italic></bold> are all multivariate normal: <inline-formula><mml:math id="me50"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>h</mml:mi></mml:mstyle><mml:mo>&#x223C;</mml:mo><mml:mtext>N</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mo>&#xA0;</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>H</mml:mi></mml:mstyle><mml:msubsup><mml:mi>&#x3C3;</mml:mi><mml:mi>h</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, <bold><inline-formula><mml:math id="me51"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>g</mml:mi></mml:mstyle><mml:mo>&#x223C;</mml:mo><mml:mtext>N</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>A</mml:mi></mml:mstyle><mml:msubsup><mml:mi>&#x3C3;</mml:mi><mml:mi>g</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula></bold>, <inline-formula><mml:math id="me52"><mml:mrow><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>b</mml:mi></mml:mstyle><mml:mo>&#x223C;</mml:mo><mml:mtext>N</mml:mtext><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mi>A</mml:mi></mml:mstyle><mml:msubsup><mml:mi>&#x3C3;</mml:mi><mml:mi>b</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, where <bold>H</bold> is a covariance structure describing covariances between the environment effects (this can be a covariance structure based on spatial information) and <bold>A</bold> is a covariance structure describing covariances between levels of the random effects <bold>g</bold> and <bold>b</bold> (<bold>A</bold> could be either a pedigree or marker-derived relationship matrix). Independence between the effects of the levels of any of the random effects can be obtained by setting either <bold>A</bold> or <bold>H</bold> to be an identity matrix. The variance components <inline-formula><mml:math id="me53"><mml:mrow><mml:msubsup><mml:mi>&#x3C3;</mml:mi><mml:mi>h</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="me54"><mml:mrow><mml:msubsup><mml:mi>&#x3C3;</mml:mi><mml:mi>g</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="me55"><mml:mrow><mml:msubsup><mml:mi>&#x3C3;</mml:mi><mml:mi>b</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> are assigned scaled-inverse-<inline-formula><mml:math id="me56"><mml:mrow><mml:msup><mml:mi>&#x3C7;</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:math></inline-formula> distributions whose shape are controlled by variance-specific degree of freedom and scale hyper-parameters. The FW package offers users the possibility of specifying hyper-parameters (degree of freedom and scale parameters); however, if these are not specified, specific sets of rules similar to those described in <xref rid="bib9" ref-type="bibr">P&#xE9;rez <italic>et al.</italic> (2010</xref>) are used to determine those parameters. Further details about this are given in Supporting Information, <ext-link ext-link-type="uri" xlink:href="http://www.g3journal.org/lookup/suppl/doi:10.1534/g3.115.026328/-/DC1/FileS2.pdf">File S2</ext-link>.</p>
        <p>In the model described above the posterior density does not have a closed form; however, estimates of features of the posterior distribution (<italic>e.g.</italic>, posterior means, posterior standard deviations, or credibility regions) can be derived using Monte Carlo methods. The FW package draws samples from the posterior distribution of the model using a Gibbs sampler (<xref rid="bib1" ref-type="bibr">Casella and George 1992</xref>; <xref rid="bib6" ref-type="bibr">Geman and Geman 1984</xref>) similar to the one described in <xref rid="bib14" ref-type="bibr">Su <italic>et al.</italic> (2006</xref>); details of the implementation of Gibbs sampler are provided in <ext-link ext-link-type="uri" xlink:href="http://www.g3journal.org/lookup/suppl/doi:10.1534/g3.115.026328/-/DC1/FileS1.pdf">File S1</ext-link>.</p>
      </sec>
    </sec>
    <sec id="s4">
      <title>Software</title>
      <p>The FW package implements both a two-step OLS method and the Bayesian method described in the previous section. Typing the following command in R will install the package:</p>
      <boxed-text id="box1" position="float">
        <table-wrap id="d36e1465" position="anchor">
          <table frame="hsides" rules="groups">
            <tbody>
              <tr>
                <td rowspan="1" colspan="1">
                  <monospace>library(devtools)</monospace>
                </td>
              </tr>
              <tr>
                <td rowspan="1" colspan="1">
                  <monospace>install_github(&#x201C;lian0090/FW&#x201D;)</monospace>
                </td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
      </boxed-text>
      <sec id="s5">
        <title>Wheat data set</title>
        <p>The package includes a data set that can be used to run examples. The data set [originally made publicly available by <xref rid="bib3" ref-type="bibr">Crossa <italic>et al.</italic> (2010</xref>)] contains data for 599 wheat lines from CIMMYT&#x2019;s Global Wheat Program evaluated for grain yield in four environments. The data set becomes available in the R environment by running the following R-code:</p>
        <boxed-text id="box2" position="float">
          <table-wrap id="d36e1488" position="anchor">
            <table frame="hsides" rules="groups">
              <tbody>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>library(FW)</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>data(wheat)</monospace>
                  </td>
                </tr>
              </tbody>
            </table>
          </table-wrap>
        </boxed-text>
        <p>Function <monospace>library()</monospace> loads the package, and <monospace>data()</monospace> loads data sets included in the package into the environment. The above code loads the following objects into the environment: (1) <monospace>wheat.Y</monospace>, a data.frame (2396 &#xD7; 3) containing the grain yield (average of two plot records, <monospace>$y</monospace>) of 599 wheat lines (<monospace>$VAR</monospace>) in four environments (<monospace>$ENV</monospace>) and (2) <monospace>wheat.G</monospace> (599 &#xD7; 599) is a genomic relationship matrix computed from DArT markers. Further details about this data set can be found in <xref rid="bib3" ref-type="bibr">Crossa <italic>et al.</italic> (2010)</xref>.</p>
      </sec>
      <sec id="s6">
        <title>User interface</title>
        <p>All the arguments of the FW function have default values, except the response variable and the corresponding identifiers for varieties and environments. A basic call to the FW program is given in <xref ref-type="boxed-text" rid="box1">Box 1</xref>.</p>
        <boxed-text id="box3" position="float">
          <caption>
            <title>
              <monospace>Box 1 Basic call of the FW function</monospace>
            </title>
          </caption>
          <table-wrap id="d36e1541" position="anchor">
            <table frame="hsides" rules="groups">
              <tbody>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>1</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>library(FW)</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>2</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>data(wheat)</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>3</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>attach(wheat.Y)</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>4</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>lm1 = FW(y = y,VAR = VAR,ENV = ENV,method=&#x201D;OLS&#x201D;)</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>5</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>lm2 = FW(y = y,VAR = VAR,ENV = ENV)</monospace>
                  </td>
                </tr>
              </tbody>
            </table>
          </table-wrap>
        </boxed-text>
        <p>When the call of the FW function is done using the code in line 4 of <xref ref-type="boxed-text" rid="box1">Box 1</xref>, FW fits a Finlay&#x2013;Wilkinson regression with the two-step OLS method: <monospace>y</monospace> (numeric, <italic>n</italic>, NAs are allowed) is the response variable, <monospace>VAR</monospace> (character, <italic>n</italic>, NAs are not allowed) are the identifiers for the varieties which are treated as labels; <monospace>ENV</monospace> (character, <italic>n</italic>, NAs are not allowed) are the identifiers for the environments; method is used to describe what method to use: <monospace>&#x201C;OLS&#x201D;</monospace> for ordinary least squares. The default method (<monospace>&#x201C;Gibbs&#x201D;</monospace>) is the Bayesian regression; this can be invoked using the code in line 5 of <xref ref-type="boxed-text" rid="box1">Box 1</xref>. By default, a single chain of Gibbs sampler is run with a total of 5000 cycles and the samples from the first 3000 cycles are used for Burn-in, and samples from the remaining 2000 cycles for inference (the user is advised to run longer chains and to check convergence as well as the size of Monte Carlo errors). The FW function provides many additional arguments that can be used to specify the model (<italic>e.g.</italic>, providing covariance matrices for varieties and environments, user-defined values for hyperparameters) and the algorithm (number of chains, number of iterations, <italic>etc</italic>.); details can be found in the user manual and in the examples presented below.</p>
        <p>After fitting either OLS or Gibbs method, FW function returns a list with estimates and arguments used in the call; a brief description of the outputs follows.</p>
      </sec>
      <sec id="s7">
        <title>Return</title>
        <p><xref ref-type="boxed-text" rid="box2">Box 2</xref> shows the structure of the object returned after calling the FW function with the default Gibbs method (see line 1 of <xref ref-type="boxed-text" rid="box2">Box 2</xref>). The first element <monospace>$y</monospace> of the list is the response vector used in the call to FW, <monospace>$whichNa</monospace> gives the position of the entries in y that were missing, <monospace>$mu</monospace> (vector), <monospace>$g</monospace> (matrix), <monospace>$b</monospace> (matrix), <monospace>$h</monospace> (matrix) are the estimated posterior means of <italic>&#x3BC;</italic>, <bold>g</bold>, <bold>b</bold>, and <bold>h</bold>; <monospace>$yhat</monospace> (matrix) is the estimated posterior means of the predictor <inline-formula><mml:math id="me58"><mml:mstyle mathvariant="bold" mathsize="normal"><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mstyle></mml:math></inline-formula>: <inline-formula><mml:math id="me59"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi><mml:mi>k</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mover accent="true"><mml:mi>&#x3BC;</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>+</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>g</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mover accent="true"><mml:mi>b</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>; <monospace>$SD.mu</monospace> (vector), <monospace>$SD.g</monospace> (matrix), <monospace>$SD.b</monospace> (matrix), <monospace>$SD.h</monospace> (matrix), and <monospace>$SD.yhat</monospace> are the estimated posterior standard deviation for <italic>&#x3BC;</italic>, <bold>g</bold>, <bold>b</bold>, <bold>h</bold>, and <bold><inline-formula><mml:math id="me61"><mml:mrow><mml:mi>&#x3BC;</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>g</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi>h</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula></bold>, respectively.</p>
        <p>With the OLS method, <monospace>$g</monospace>, <monospace>$b</monospace>, <monospace>$h</monospace>, and <monospace>$yhat</monospace> all have only one column; with the Gibbs method each column provides estimates derived from one chain of Markov chain Monte Carlo (MCMC). Since the default behavior is to run only one chain the outputs in <xref ref-type="boxed-text" rid="box2">Box 2</xref> contain only one column; however, if multiple chains are run, estimates from different chains are provided in different columns.</p>
        <boxed-text id="box4" position="float">
          <caption>
            <title>
              <monospace>Box 2 Structure of the object returned by FW</monospace>
            </title>
          </caption>
          <table-wrap id="d36e1820" position="float">
            <table frame="hsides" rules="groups">
              <tbody>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>
                      <monospace>1</monospace>
                    </monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>str(lm2)</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>2</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>List of 24</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>3</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>$ y: num [1:2396] 6.17 3.14 2.74 3.26 4.99 ...</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>4</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>$ whichNa: int(0)</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>5</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>$ VAR: chr [1:2396] &#x201C;775&#x201D; &#x201C;775&#x201D; &#x201C;775&#x201D; &#x201C;775&#x201D; ...</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>6</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>$ ENV: chr [1:2396] &#x201C;1&#x201D; &#x201C;2&#x201D; &#x201C;4&#x201D; &#x201C;5&#x201D; ...</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>7</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>$ mu: Named num 4.64</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>8</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>$ SD.mu: Named num 0.0979</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>9</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>$ g: num [1:599, 1] -0.476 0.16 -0.611 ...</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>10</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>$ SD.g: num [1:599, 1] 0.224 0.219 0.224 0.208 ...</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>11</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>$ b: num [1:599, 1] 0.1604 -0.1255 0.251 ...</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>12</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>$ SD.b: num [1:599, 1] 0.237 0.236 0.235 0.24 ...</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>13</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>$ h: num [1:4, 1] 0.519 -0.186 -0.776 -1.383 ...</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>14</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>$ SD.h: num [1:4, 1] 0.096 0.0999 0.0999 0.103 ...</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>15</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>$ yhat: num [1:2396, 1] 5.17 4.3 3.56 2.81 5.21 ...</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>16</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>$ SD.yhat: num [1:2396, 1] 0.283 0.217 0.25 0.343 ...</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>17</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>$ var_e: Named num 0.3</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>18</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>$ SD.var_e: Named num 0.0111</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>19</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>$ var_g: Named num 0.0885</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>20</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>$ SD.var_g: Named num 0.0116</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>21</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>$ var_b: Named num 0.0973</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>22</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>$ SD.var_b: Named num 0.0132</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>23</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>$ var_h: Named num 0.926</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>24</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>$ SD.var_h: Named num 0.595</monospace>
                  </td>
                </tr>
              </tbody>
            </table>
          </table-wrap>
        </boxed-text>
        <p>The outputs <monospace>$var_e</monospace>, <monospace>$var_g</monospace>, <monospace>$var_b</monospace>, and <monospace>$var_h</monospace> are the estimated posterior means for <inline-formula><mml:math id="me62"><mml:mrow><mml:msubsup><mml:mi>&#x3C3;</mml:mi><mml:mi>&#x3B5;</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="me63"><mml:mrow><mml:msubsup><mml:mi>&#x3C3;</mml:mi><mml:mi>g</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="me64"><mml:mrow><mml:msubsup><mml:mi>&#x3C3;</mml:mi><mml:mi>b</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="me65"><mml:mrow><mml:msubsup><mml:mi>&#x3C3;</mml:mi><mml:mi>h</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> (only available for the Gibbs method). Each element of <monospace>$var_e</monospace>, <monospace>$var_g</monospace>, <monospace>$var_b</monospace>, and <monospace>$var_h</monospace> correspond to estimates derived from different chains; <monospace>$SD.var_e</monospace>, <monospace>$SD.var_g</monospace>, <monospace>$SD.var_b</monospace>, and <monospace>$SD.var_h</monospace> are the estimated posterior standard deviation for <inline-formula><mml:math id="me66"><mml:mrow><mml:msubsup><mml:mi>&#x3C3;</mml:mi><mml:mi>&#x3B5;</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="me67"><mml:mrow><mml:msubsup><mml:mi>&#x3C3;</mml:mi><mml:mi>g</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="me68"><mml:mrow><mml:msubsup><mml:mi>&#x3C3;</mml:mi><mml:mi>b</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>, and <inline-formula><mml:math id="me69"><mml:mrow><mml:msubsup><mml:mi>&#x3C3;</mml:mi><mml:mi>h</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>, respectively.</p>
      </sec>
      <sec id="s8">
        <title>Output files</title>
        <p>No output files are generated for the OLS method. For the Gibbs method, samples for <inline-formula><mml:math id="me70"><mml:mrow><mml:msubsup><mml:mi>&#x3C3;</mml:mi><mml:mi>&#x3B5;</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="me71"><mml:mrow><mml:msubsup><mml:mi>&#x3C3;</mml:mi><mml:mi>g</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="me72"><mml:mrow><mml:msubsup><mml:mi>&#x3C3;</mml:mi><mml:mi>b</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="me73"><mml:mrow><mml:msubsup><mml:mi>&#x3C3;</mml:mi><mml:mi>h</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>, and (by default) the first two elements of <bold>g, b,</bold> and <bold>h</bold> will be saved; as the Gibbs sampler collects samples, these samples are saved to the hard drive (only the most recent samples are retained in the memory); by default, a thinning of 5 is used. Once the iteration process finishes, FW will read all the saved samples into a <monospace>mcmc</monospace> object, save the <monospace>mcmc</monospace> object into a file <monospace>samps.rda</monospace>, and remove the raw sample files. To prevent overloading the RAM with samples by default FW only save samples of the first two entries of the vectors of random effects; however the user can change this behavior by specifying which entries of the vectors are desired using the <monospace>saveVAR</monospace> (for <bold>g</bold> and <bold>b</bold>) and <monospace>saveENV</monospace> (for <bold>h</bold>) argument. These samples produced by FW can be used to assess convergence and to estimate Monte Carlo standard errors. The file <monospace>samps.rda</monospace> can be directly loaded into R using load(<monospace>&#x2019;samps.rda&#x2019;</monospace>). Once the object containing the samples is loaded in the R environment, the package coda (<xref rid="bib11" ref-type="bibr">Plummer <italic>et al.</italic>, 2006</xref>) can be used to obtain plots of the chains and compute convergence diagnostics.</p>
      </sec>
    </sec>
    <sec id="s9">
      <title>Application examples</title>
      <p>In this section we illustrate via examples some of the features of the FW package. Example 1 illustrates how the package can be used to fit Finlay&#x2013;Wilkinson regression by the OLS method and Gibbs method with and without covariance structure and Example 2 describes how the package can be used for cross-validation analyses. Additional examples involving fine-tuning the Gibbs method (<italic>e.g.</italic>, hyperparameter setup, fitting more than two chains, specify saved samples) are provided in <ext-link ext-link-type="uri" xlink:href="http://www.g3journal.org/lookup/suppl/doi:10.1534/g3.115.026328/-/DC1/FileS2.pdf">File S2</ext-link>.</p>
      <sec id="s10">
        <title>Example 1: fitting models with default setup for 599 wheat lines</title>
        <p><xref ref-type="boxed-text" rid="box3">Box 3</xref> shows the code used to fit a FW regression using three different approaches: (1) a two-step OLS method (code in line 3), (2) a Bayesian FW regression assuming independence of lines and of environments (code in lines 3&#x2013;5), and (3) a Bayesian FW regression that incorporates genomic information (lines 6&#x2013;8). In the Bayesian models, the seed for the random number generator can be specified using the argument seed (see lines 3&#x2013;8) and the argument saveAt can be used to add a path and a prefix to be appended to <monospace>&#x2019;samps.rda&#x2019;</monospace> file.</p>
        <boxed-text id="box5" position="float">
          <caption>
            <title>
              <monospace>Box 3 Fit models by default parameters</monospace>
            </title>
          </caption>
          <table-wrap id="d36e2241" position="anchor">
            <table frame="hsides" rules="groups">
              <tbody>
                <tr>
                  <td rowspan="1" colspan="1">1</td>
                  <td rowspan="1" colspan="1">library(FW); data(wheat); attach(wheat.Y)</td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">2</td>
                  <td rowspan="1" colspan="1">OLS = FW(y = y,VAR = VAR,ENV = ENV, method=&#x201D;OLS&#x201D;)</td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">3</td>
                  <td rowspan="1" colspan="1">GibbsI = FW(y = y,VAR = VAR,ENV = ENV,</td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">4</td>
                  <td rowspan="1" colspan="1">method=&#x201D;Gibbs&#x201D;,seed = 12345,saveAt=&#x201D;GibbsI&#x201D;,nIter = 50000</td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">5</td>
                  <td rowspan="1" colspan="1">,burnIn = 5000)</td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">6</td>
                  <td rowspan="1" colspan="1">GibbsA = FW(y = y,VAR = VAR,ENV = ENV,</td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">7</td>
                  <td rowspan="1" colspan="1">method=&#x201D;Gibbs&#x201D;,A = wheat.G,seed = 12345,</td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">8</td>
                  <td rowspan="1" colspan="1">saveAt=&#x201D;GibbsA&#x201D;,nIter = 50000,burnIn = 5000)</td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">9</td>
                  <td rowspan="1" colspan="1">load(&#x201C;GibbsIsamps.rda&#x201D;)</td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">10</td>
                  <td rowspan="1" colspan="1">HPDinterval(samps[,c(&#x201C;var_e&#x201D;,&#x201D;var_g&#x201D;,&#x201D;var_b&#x201D;,&#x201D;var_h&#x201D;)])</td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">11</td>
                  <td rowspan="1" colspan="1">load(&#x201C;GibbsAsamps.rda&#x201D;)</td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">12</td>
                  <td rowspan="1" colspan="1">HPDinterval(samps[,c(&#x201C;var_e&#x201D;,&#x201D;var_g&#x201D;,&#x201D;var_b&#x201D;,&#x201D;var_h&#x201D;)])</td>
                </tr>
              </tbody>
            </table>
          </table-wrap>
        </boxed-text>
        <p>Parameter estimates (estimated posterior means) can be directly extracted from the FW object as illustrated in <xref ref-type="boxed-text" rid="box2">Box 2</xref>. Other features of the posterior distribution (<italic>e.g.</italic>, 95% credibility intervals for the parameters) can be obtained by <italic>post hoc</italic> analyses of the samples included in the rda file generated by the program (see lines 9&#x2013;12 of <xref ref-type="boxed-text" rid="box3">Box 3</xref>). In <xref ref-type="table" rid="t1">Table 1</xref>, we listed the estimates of variance components from the three models. For the OLS method, only the residual variance <inline-formula><mml:math id="me74"><mml:mrow><mml:msubsup><mml:mi>&#x3C3;</mml:mi><mml:mi>&#x3B5;</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> (weighted mean of residual variance for each within-line regression by its residual degree of freedom) is estimated. The estimated error variances are very similar across the three models. Also from <xref ref-type="table" rid="t1">Table 1</xref>, we can see that the estimated variance of the main effects of the environments is large relative to both the error variance and the phenotypic variance.</p>
        <table-wrap id="t1" position="float">
          <label>Table 1</label>
          <caption>
            <title>Estimated variance components (posterior 95% credibility intervals in parentheses) from different models</title>
          </caption>
          <table frame="hsides" rules="groups">
            <col width="12.37%" span="1"/>
            <col width="32.44%" span="1"/>
            <col width="10.41%" span="1"/>
            <col width="22.39%" span="1"/>
            <col width="22.39%" span="1"/>
            <thead>
              <tr>
                <th valign="top" align="center" scope="col" rowspan="1" colspan="1">Parameters</th>
                <th valign="top" align="center" scope="col" rowspan="1" colspan="1">FW Output</th>
                <th valign="top" align="center" scope="col" rowspan="1" colspan="1">OLS</th>
                <th valign="top" align="center" scope="col" rowspan="1" colspan="1">GibbsI (A = I)</th>
                <th valign="top" align="center" scope="col" rowspan="1" colspan="1">GibbsA (A = G)</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td valign="top" align="left" scope="row" rowspan="1" colspan="1">
                  <inline-formula>
                    <mml:math id="me75">
                      <mml:mrow>
                        <mml:msubsup>
                          <mml:mi>&#x3C3;</mml:mi>
                          <mml:mi>&#x3B5;</mml:mi>
                          <mml:mn>2</mml:mn>
                        </mml:msubsup>
                      </mml:mrow>
                    </mml:math>
                  </inline-formula>
                </td>
                <td valign="top" align="left" rowspan="1" colspan="1"><monospace>$var_e</monospace> (Gibbs) <monospace>$var_e_weighted</monospace>(OLS)</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.32</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.30 (0.28, 0.32)</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.30 (0.28, 0.32)</td>
              </tr>
              <tr>
                <td valign="top" align="left" scope="row" rowspan="1" colspan="1">
                  <inline-formula>
                    <mml:math id="me76">
                      <mml:mrow>
                        <mml:msubsup>
                          <mml:mi>&#x3C3;</mml:mi>
                          <mml:mi>g</mml:mi>
                          <mml:mn>2</mml:mn>
                        </mml:msubsup>
                      </mml:mrow>
                    </mml:math>
                  </inline-formula>
                </td>
                <td valign="top" align="left" rowspan="1" colspan="1">
                  <monospace>$var_g</monospace>
                </td>
                <td valign="top" align="center" rowspan="1" colspan="1">NA</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.09 (0.07, 0.11)</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.11 (0.08, 0.14)</td>
              </tr>
              <tr>
                <td valign="top" align="left" scope="row" rowspan="1" colspan="1">
                  <inline-formula>
                    <mml:math id="me77">
                      <mml:mrow>
                        <mml:msubsup>
                          <mml:mi>&#x3C3;</mml:mi>
                          <mml:mi>b</mml:mi>
                          <mml:mn>2</mml:mn>
                        </mml:msubsup>
                      </mml:mrow>
                    </mml:math>
                  </inline-formula>
                </td>
                <td valign="top" align="left" rowspan="1" colspan="1">
                  <monospace>$var_b</monospace>
                </td>
                <td valign="top" align="center" rowspan="1" colspan="1">NA</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.10 (0.07, 0.12)</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.13 (0.10, 0.17)</td>
              </tr>
              <tr>
                <td valign="top" align="left" scope="row" rowspan="1" colspan="1">
                  <inline-formula>
                    <mml:math id="me78">
                      <mml:mrow>
                        <mml:msubsup>
                          <mml:mi>&#x3C3;</mml:mi>
                          <mml:mi>h</mml:mi>
                          <mml:mn>2</mml:mn>
                        </mml:msubsup>
                      </mml:mrow>
                    </mml:math>
                  </inline-formula>
                </td>
                <td valign="top" align="left" rowspan="1" colspan="1">
                  <monospace>$var_h</monospace>
                </td>
                <td valign="top" align="center" rowspan="1" colspan="1">NA</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.90 (0.24, 1.90)</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.88 (0.24, 1.88)</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <p>The fitness of the models can be examined by the correlations between the observed values y and the fitted values <inline-formula><mml:math id="me79"><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> (line 1 of <xref ref-type="boxed-text" rid="box4">Box 4</xref>). The OLS model fitted the data better than both GibbsI and GibbsA: the correlation was 0.91 for the OLS method, 0.88 for GibbsI, and 0.86 for GibbsA.</p>
        <boxed-text id="box6" position="float">
          <caption>
            <title>
              <monospace>Box 4 Correlation between <italic>y</italic> and <inline-formula><mml:math id="me102"><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula>, and correlations for <inline-formula><mml:math id="me100"><mml:mrow><mml:mover accent="true"><mml:mi>b</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> among different models</monospace>
            </title>
          </caption>
          <table-wrap id="d36e2488" position="anchor">
            <table frame="hsides" rules="groups">
              <tbody>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>1</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>cor(y,OLS$yhat);cor(y,GibbsI$yhat);cor(y,GibbsA$yhat);</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>2</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>cor(OLS$b,GibbsI$b);cor(OLS$b,GibbsA$b);cor(GibbsI$b,GibbsA$b)</monospace>
                  </td>
                </tr>
              </tbody>
            </table>
          </table-wrap>
        </boxed-text>
        <p>In <xref ref-type="table" rid="t2">Table 2</xref>, we listed the correlations among parameter estimates from different models (code for <inline-formula><mml:math id="me80"><mml:mover accent="true"><mml:mi>b</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:math></inline-formula> was provided in line 2 of <xref ref-type="boxed-text" rid="box4">Box 4</xref>), and noticed that correlations among parameter estimates from different models are high; this is expected considering that the data comes from a full factorial design where all lines are evaluated in all environments.</p>
        <table-wrap id="t2" position="float">
          <label>Table 2</label>
          <caption>
            <title>Pearson&#x2019;s product-moment correlation between parameter estimates derived by each of the three methods implemented in Box 3</title>
          </caption>
          <table frame="hsides" rules="groups">
            <col width="23.43%" span="1"/>
            <col width="23.69%" span="1"/>
            <col width="24.79%" span="1"/>
            <col width="28.09%" span="1"/>
            <thead>
              <tr>
                <th valign="top" align="left" scope="col" rowspan="1" colspan="1"/>
                <th valign="top" align="center" scope="col" rowspan="1" colspan="1">OLS&#x2013;GibbsI</th>
                <th valign="top" align="center" scope="col" rowspan="1" colspan="1">OLS&#x2013;GibbsA</th>
                <th valign="top" align="center" scope="col" rowspan="1" colspan="1">GibbsI&#x2013;GibbsA</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td valign="top" align="left" scope="row" rowspan="1" colspan="1">
                  <inline-formula>
                    <mml:math id="me81">
                      <mml:mover accent="true">
                        <mml:mi>h</mml:mi>
                        <mml:mo>^</mml:mo>
                      </mml:mover>
                    </mml:math>
                  </inline-formula>
                </td>
                <td valign="top" align="center" rowspan="1" colspan="1">1.00</td>
                <td valign="top" align="center" rowspan="1" colspan="1">1.00</td>
                <td valign="top" align="center" rowspan="1" colspan="1">1.00</td>
              </tr>
              <tr>
                <td valign="top" align="left" scope="row" rowspan="1" colspan="1">
                  <inline-formula>
                    <mml:math id="me82">
                      <mml:mover accent="true">
                        <mml:mi>b</mml:mi>
                        <mml:mo>^</mml:mo>
                      </mml:mover>
                    </mml:math>
                  </inline-formula>
                </td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.94</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.81</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.83</td>
              </tr>
              <tr>
                <td valign="top" align="left" scope="row" rowspan="1" colspan="1">
                  <inline-formula>
                    <mml:math id="me83">
                      <mml:mover accent="true">
                        <mml:mi>g</mml:mi>
                        <mml:mo>^</mml:mo>
                      </mml:mover>
                    </mml:math>
                  </inline-formula>
                </td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.98</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.79</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.81</td>
              </tr>
              <tr>
                <td valign="top" align="left" scope="row" rowspan="1" colspan="1">
                  <inline-formula>
                    <mml:math id="me84">
                      <mml:mover accent="true">
                        <mml:mi>y</mml:mi>
                        <mml:mo>^</mml:mo>
                      </mml:mover>
                    </mml:math>
                  </inline-formula>
                </td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.96</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.94</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.97</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <p>The pattern of variety performance in different environments can be visualized by plotting the observed and fitted values against the estimated environment effects. <xref ref-type="fig" rid="fig1">Figure 1</xref> was generated by the calling of plot function in line 2&#x2013;3 of <xref ref-type="boxed-text" rid="box5">Box 5</xref>. Each line in this plot corresponds to a genotype. The comparison of the results from the OLS and GibbsA reveals interesting patterns: the OLS method predicts a much stronger extent of variability in intercepts and slopes (this is likely due to overfitting, see Example 2 below) than the Bayesian method. The Bayesian method yields &#x2018;smoother&#x2019; predictions; this is a direct consequence of the shrinkage-toward-the-mean induced in the Bayesian method by treating effects as random and the use of correlations between genotypes (<italic>e.g.</italic>, genomic relationships).</p>
        <fig id="fig1" fig-type="figure" position="float">
          <label>Figure 1</label>
          <caption>
            <p>Plot of variety performance <italic>vs.</italic> estimated environment values. Each line represents a different variety. Lines are fitted values and points are the cell means of genotype and environment combination. The horizontal axis displays the estimated environmental effects. The labels of these environments are also displayed; these labels can be removed by setting <monospace>ENVlabel = F</monospace>.</p>
          </caption>
          <graphic xlink:href="589f1"/>
        </fig>
        <p>The function plotVAR also allows users to display the curves for a few genotypes (see code in lines 5&#x2013;9 of <xref ref-type="boxed-text" rid="box5">Box 5</xref>). Using this feature we display in <xref ref-type="fig" rid="fig2">Figure 2</xref> the estimated regressions for five varieties. The slope in the plot corresponds to <inline-formula><mml:math id="me85"><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and the dashed line corresponds to a slope equal to 1 (<inline-formula><mml:math id="me86"><mml:mrow><mml:msub><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>); recall that <inline-formula><mml:math id="me87"><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msub><mml:mi>b</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> represents the expected change in performance of the i<sup>th</sup> variety per unit change in the environment effect. We observe from <xref ref-type="fig" rid="fig2">Figure 2</xref> that line ID = 1081265 performs well in all environments and line ID = 13302 is better adapted to good environments.</p>
        <fig id="fig2" fig-type="figure" position="float">
          <label>Figure 2</label>
          <caption>
            <p>Plot of the performance of five varieties on estimated environment values. Each color represents a different variety. Lines are fitted values and circles are the cell means of genotype by environment combination. The horizontal axis displays the estimated environmental effects. The labels of these environments are also displayed; these labels can be removed by setting <monospace>ENVlabel = F</monospace>.</p>
          </caption>
          <graphic xlink:href="589f2"/>
        </fig>
      </sec>
      <sec id="s11">
        <title>Fitting models with covariance between the environment effects</title>
        <p>Covariance structures can be used to induce borrowing of information between levels of a random effect. For instance, pedigree-based or genomic-derived relationships can be used to induce borrowing of information between genotypes. Similarly a covariance structure between the environment effects could be used to induce borrowing of information between environments. Such covariance structures can be derived from previous knowledge about the correlation of the average performance of genotypes in pairs of environments or by using environmental covariates, as demonstrated in <xref rid="bib8" ref-type="bibr">Jarqu&#xED;n <italic>et al.</italic> (2014</xref>). The FW package allows incorporating covariance between the environment effects; an example of how this can be done is given in <xref ref-type="boxed-text" rid="box6">Box 6</xref>. In this example we compare three analyses. The first model (GibbsI) assumes that the environment effects are independent; this model was fitted previously using the code in <xref ref-type="boxed-text" rid="box3">Box 3</xref>. Subsequently, we modified this model by incorporating a covariance structure that assumes a covariance of 0.9 between environments 1 and 2, and null covariance among the other pairs of environments. This model was fitted using the entire data set (GibbsH) and after setting to NA all the records from the 2nd environment (GibbsH_NA).</p>
        <boxed-text id="box7" position="float">
          <caption>
            <title>
              <monospace>Box 5 Plot fitted models</monospace>
            </title>
          </caption>
          <table-wrap id="d36e2712" position="anchor">
            <table frame="hsides" rules="groups">
              <tbody>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>1</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>par(mfrow = c(1,2))</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>2</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>plot(OLS,main=&#x201D;OLS&#x201D;, cex = 0.2,lwd = 0.2)</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>3</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>plot(GibbsA,main=&#x201D;GibbsA&#x201D;, cex = 0.2,lwd = 0.2) #cex controls point</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>4</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>#size, lwd controls the line width</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>5</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>plot(OLS, plotVAR = c(&#x201C;1081265&#x201D;,&#x201D;1101307&#x201D;,</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>6</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>&#x201C;1295736&#x201D;, &#x201C;13302&#x201D;, &#x201C;1343502&#x201D;), main=&#x201D;OLS&#x201D;)</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>7</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>plot(GibbsA, plotVAR = c(&#x201C;1081265&#x201D;,&#x201D;1101307&#x201D;,</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>8</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>&#x201C;1295736&#x201D;, &#x201C;13302&#x201D;, &#x201C;1343502&#x201D;),</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>9</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>main=&#x201D;GibbsA&#x201D;)</monospace>
                  </td>
                </tr>
              </tbody>
            </table>
          </table-wrap>
        </boxed-text>
        <p><xref ref-type="table" rid="t3">Table 3</xref> displays the estimated environment effects derived from each of the analyses. The estimated environment effects derived from GibbsI and GibbsH were almost identical. This happens because in these two examples the data available for each environment dominate over the prior distribution (which in case of GibssH assumes that the effects of environments 1 and 2 are highly correlated). However, when we set to NA all the entries of environment 2 (GibbsH_NA), the estimated effects for environments 1 and 2 are very close. This was entirely driven by the covariance structure H. An intermediate situation can emerge where one environment has records for a few genotypes. In such cases, nondiagonal covariance structures (H) may be used to borrow information between environments.</p>
        <table-wrap id="t3" position="float">
          <label>Table 3</label>
          <caption>
            <title>Estimated environment effects from GibbsI and GibbsH</title>
          </caption>
          <table frame="hsides" rules="groups">
            <col width="10.93%" span="1"/>
            <col width="29.69%" span="1"/>
            <col width="29.69%" span="1"/>
            <col width="29.69%" span="1"/>
            <thead>
              <tr>
                <th valign="top" align="center" scope="col" rowspan="1" colspan="1">ENV</th>
                <th valign="top" align="center" scope="col" rowspan="1" colspan="1">GibbsI</th>
                <th valign="top" align="center" scope="col" rowspan="1" colspan="1">GibbsH</th>
                <th valign="top" align="center" scope="col" rowspan="1" colspan="1">GibbsH_NA</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td valign="top" align="left" scope="row" rowspan="1" colspan="1">1</td>
                <td valign="top" align="char" char="." rowspan="1" colspan="1">0.52</td>
                <td valign="top" align="char" char="." rowspan="1" colspan="1">0.51</td>
                <td valign="top" align="char" char="." rowspan="1" colspan="1">0.78</td>
              </tr>
              <tr>
                <td valign="top" align="left" scope="row" rowspan="1" colspan="1">2</td>
                <td valign="top" align="char" char="." rowspan="1" colspan="1">&#x2212;0.18</td>
                <td valign="top" align="char" char="." rowspan="1" colspan="1">&#x2212;0.19</td>
                <td valign="top" align="char" char="." rowspan="1" colspan="1">0.74</td>
              </tr>
              <tr>
                <td valign="top" align="left" scope="row" rowspan="1" colspan="1">4</td>
                <td valign="top" align="char" char="." rowspan="1" colspan="1">&#x2212;0.78</td>
                <td valign="top" align="char" char="." rowspan="1" colspan="1">&#x2212;0.78</td>
                <td valign="top" align="char" char="." rowspan="1" colspan="1">&#x2212;0.52</td>
              </tr>
              <tr>
                <td valign="top" align="left" scope="row" rowspan="1" colspan="1">5</td>
                <td valign="top" align="char" char="." rowspan="1" colspan="1">&#x2212;1.38</td>
                <td valign="top" align="char" char="." rowspan="1" colspan="1">&#x2212;1.39</td>
                <td valign="top" align="char" char="." rowspan="1" colspan="1">&#x2212;1.11</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
        <boxed-text id="box8" position="float">
          <caption>
            <title>
              <monospace>Box 6 Including covariance matrix (H) for environments in FW</monospace>
            </title>
          </caption>
          <table-wrap id="d36e2844" position="anchor">
            <table frame="hsides" rules="groups">
              <tbody>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>1</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>H = diag(1,4)</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>2</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>H[1,2]=H[2,1]=0.9</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>3</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>colnames(H)=rownames(H)=c(1,2,4,5)</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>4</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>GibbsH = FW(y = y,VAR = VAR,ENV = ENV, method=&#x201C;Gibbs&#x201D;,H = H,seed =</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>5</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>&#x2003;12345,nIter = 50000,burnIn = 5000)</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>6</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>yNA = y</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>7</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>yNA[which(ENV==2)]=NA</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>8</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>GibbsH_NA = FW(y = yNA,VAR = VAR,ENV = ENV, method=&#x201C;Gibbs&#x201D;,H = H,seed =</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>9</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>&#x2003;12345,nIter = 50000,burnIn = 5000)</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>10</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>round(cbind(GibbsI$h,GibbsH$h,GibbsH_NA$h),2)</monospace>
                  </td>
                </tr>
              </tbody>
            </table>
          </table-wrap>
        </boxed-text>
        <p>Finally, the example provided by GibbsH_NA also illustrates how H allows predictions to be made about environments without records; if such environments are correlated with other environments for which we have data, in principle we can infer the effects for those environments. This of course will not be possible if H is diagonal.</p>
      </sec>
      <sec id="s12">
        <title>Assessment of convergence for Bayesian FW regressions</title>
        <p>The convergence of Gibbs sampler can be examined by plotting the samples collected by FW. The code in <xref ref-type="boxed-text" rid="box7">Box 7</xref> illustrates how to produce trace plots: lines 1&#x2013;2 load and plot the samples from GibbsI and lines 3&#x2013;4 do the same for GibbsA. Mixing was reasonably good (samples traverse through the sample space in relatively few steps, and can be verified by low average autocorrelation between samples: for example the average autocorrelation was 0.05 for <monospace>var_e</monospace> at lag 5, see line 5 of <xref ref-type="boxed-text" rid="box7">Box 7</xref>) in both cases for the variance components [<inline-formula><mml:math id="me88"><mml:mrow><mml:msubsup><mml:mi>&#x3C3;</mml:mi><mml:mi>&#x3B5;</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> (<monospace>var_e</monospace>), <inline-formula><mml:math id="me89"><mml:mrow><mml:msubsup><mml:mi>&#x3C3;</mml:mi><mml:mi>g</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> (<monospace>var_g</monospace>), <inline-formula><mml:math id="me90"><mml:mrow><mml:msubsup><mml:mi>&#x3C3;</mml:mi><mml:mi>b</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> (<monospace>var_b</monospace>)], genotype main effects <bold>g</bold> (<monospace>g</monospace>), genotype slope <bold>b</bold> (<monospace>b</monospace>), and the function predictor <inline-formula><mml:math id="me91"><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo>&#xA0;</mml:mo></mml:mrow></mml:math></inline-formula>(<monospace>yhat</monospace>). There are many high peaks in the trace plot of <inline-formula><mml:math id="me92"><mml:mrow><mml:msubsup><mml:mi>&#x3C3;</mml:mi><mml:mi>h</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> (<monospace>var_h</monospace>), which indicates that the distribution of <inline-formula><mml:math id="me93"><mml:mrow><mml:msubsup><mml:mi>&#x3C3;</mml:mi><mml:mi>h</mml:mi><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula> is skewed (this is also self-evident in the density plot). This should be expected since there are only four levels of environment effect and scaled-inverse chi-square distribution with few degrees of freedom is highly skewed. <xref ref-type="fig" rid="fig3">Figure 3</xref> reproduces the trace plot of the variance components (<monospace>var_e</monospace>, <monospace>var_g</monospace>, <monospace>var_b</monospace>, <monospace>var_h</monospace>).</p>
        <fig id="fig3" fig-type="figure" position="float">
          <label>Figure 3</label>
          <caption>
            <p>Trace and density plot of variance components from GibbsA.</p>
          </caption>
          <graphic xlink:href="589f3"/>
        </fig>
        <p>The mixing for the intercept <italic>&#x3BC;</italic> and the environment effects (the entries of <bold>h</bold>) can be slow in multiplicative models (<italic>e.g.</italic>, <xref rid="bib13" ref-type="bibr">Shariati <italic>et al.</italic>, 2009</xref>). Therefore, the user is advised to check convergence to the posterior distribution and the magnitude of Monte Carlo standard errors. Convergence to the posterior distribution can be assessed graphically using a trace plot for single or more formally multiple chains. <xref ref-type="fig" rid="fig4">Figure 4</xref> reproduces the trace plot for intercept <italic>&#x3BC;</italic> and the first two elements of environment effect, <monospace>h[1]</monospace> and <monospace>h[2]</monospace>; in all cases we used samples from model GibbsA. From <xref ref-type="fig" rid="fig4">Figure 4</xref>, we can see that even the mixing of <monospace>h[1]</monospace> and <monospace>h[2]</monospace> is slow; when running 50,000 iterations, the chain has converged to relative constant sample means. The Time-series standard error for the sample means of <monospace>h[1]</monospace> and <monospace>h[2]</monospace> are both around 0.0065, which is at a reasonable level (obtained by line 6 of <xref ref-type="boxed-text" rid="box7">Box 7</xref>). An example of how to assess convergence using multiple chains is provided in <ext-link ext-link-type="uri" xlink:href="http://www.g3journal.org/lookup/suppl/doi:10.1534/g3.115.026328/-/DC1/FileS2.pdf">File S2</ext-link>.</p>
        <fig id="fig4" fig-type="figure" position="float">
          <label>Figure 4</label>
          <caption>
            <p>Trace plot of the intercept (<monospace>mu</monospace>) and the first two levels of environment effects (<monospace>h[1]</monospace>) and <monospace>h[2]</monospace>) from GibbsA.</p>
          </caption>
          <graphic xlink:href="589f4"/>
        </fig>
        <boxed-text id="box9" position="float">
          <caption>
            <title>
              <monospace>Box 7 Plot of Gibbs samples</monospace>
            </title>
          </caption>
          <table-wrap id="d36e3123" position="anchor">
            <table frame="hsides" rules="groups">
              <tbody>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>1</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>load(&#x201C;GibbsIsamps.rda&#x201D;)</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>2</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>plot(samps,ask = T)</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>3</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>load(&#x201C;GibbsAsamps.rda&#x201D;)</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>4</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>plot(samps,ask = T)</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>5</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>autocorr(samps[[1]][,&#x201D;var_e&#x201D;])</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>6</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>summary(samps)</monospace>
                  </td>
                </tr>
              </tbody>
            </table>
          </table-wrap>
        </boxed-text>
      </sec>
      <sec id="s13">
        <title>Example 2: assessment of prediction accuracy in testing data sets</title>
        <p>Example 1 suggests that the OLS method fitted the training data better than the Bayesian models; this is expected because shrinkage reduces fitness to the data used to train a model. However, better model fitness does not necessarily imply higher prediction accuracy in validation data sets. In the following example we illustrate how to use the FW for assessment of prediction accuracy using cross-validation.</p>
        <p>To assess the ability of different models for predicting new data, we modified the code in <xref ref-type="boxed-text" rid="box3">Box 3</xref> by setting NA to randomly selected entries of the phenotypic vector (<italic>i.e.</italic>, one record out of four per line was randomly selected and labeled as NA; see code in lines 1&#x2013;5 in <xref ref-type="boxed-text" rid="box8">Box 8</xref>). The FW package produces estimates and predictions for all the lines, environments, and entries of the phenotypic vector, including those that had observed values and those that had NA. Therefore, predictions for entries with masked phenotypes can be used to assess prediction accuracy in validation data sets (see lines 14&#x2013;16 in <xref ref-type="boxed-text" rid="box8">Box 8</xref>). We repeated the code in <xref ref-type="boxed-text" rid="box8">Box 8</xref> 100 times and generated 100 random partitions of the data into training and testing sets. Each partition renders an estimate of prediction accuracy for each of the models.</p>
        <boxed-text id="box10" position="float">
          <caption>
            <title>
              <monospace>Box 8 Correlation between y and <inline-formula><mml:math id="me101"><mml:mrow><mml:mover accent="true"><mml:mi>y</mml:mi><mml:mo>^</mml:mo></mml:mover></mml:mrow></mml:math></inline-formula> for training and validation data sets</monospace>
            </title>
          </caption>
          <table-wrap id="d36e3203" position="anchor">
            <table frame="hsides" rules="groups">
              <tbody>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>1</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>yNA = y</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>2</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>seed = 12345; set.seed(seed)</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>3</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>#randomly masking one environment for each variety</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>4</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>whichNa = seq(from = 0,to = 2392,by = 4)+sample(1:4,size = 599,replace = T)</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>5</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>yNA[whichNa]=NA</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>6</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>OLS = FW(y = yNA,VAR = VAR,ENV = ENV, method=&#x201D;OLS&#x201D;)</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>7</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>GibbsI = FW(y = yNA,VAR = VAR,ENV = ENV,</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>8</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>method=&#x201D;Gibbs&#x201D;,seed = seed,nIter = 50000, burnIn = 5000)</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>9</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>GibbsA = FW(y = yNA,VAR = VAR,ENV = ENV,</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>10</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>method=&#x201D;Gibbs&#x201D;,A = wheat.G,seed = seed,nIter = 50000,burnIn = 5000)</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>11</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>cor(y[-whichNa],OLS$yhat[-whichNa,])</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>12</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>cor(y[-whichNa],GibbsI$yhat[-whichNa,])</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>13</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>cor(y[-whichNa],GibbsA$yhat[-whichNa,])</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>14</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>cor(y[whichNa],OLS$yhat[whichNa,])</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>15</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>cor(y[whichNa],GibbsI$yhat[whichNa,])</monospace>
                  </td>
                </tr>
                <tr>
                  <td rowspan="1" colspan="1">
                    <monospace>16</monospace>
                  </td>
                  <td rowspan="1" colspan="1">
                    <monospace>cor(y[whichNa],GibbsA$yhat[whichNa,])</monospace>
                  </td>
                </tr>
              </tbody>
            </table>
          </table-wrap>
        </boxed-text>
        <p>The mean correlation (of the 100 replicates) between phenotypes and predictions in the training data set (<italic>i.e.</italic>, for the entries of y that did not have missing values) follows the same patterns as in Example 1, where OLS fitted the data best: 0.95 for OLS, 0.89 for GibbsI, and 0.86 for GibbsA. However, the mean prediction correlation (of the 100 replicates) for the entries of the validation set has reversed orders: 0.61 for OLS, 0.77 for GibbsI, and 0.80 for GibbsA.</p>
        <p>In <xref ref-type="fig" rid="fig5">Figure 5</xref>, we plotted the estimated prediction correlation between predictions and observations in training (1st row of plots) and testing (2nd row of plots) data sets. Plots in the 1st, 2nd, and 3rd column correspond to comparisons of: OLS <italic>vs.</italic> GibbsI, OLS <italic>vs.</italic> GibbsA, and GibbsI <italic>vs.</italic> GibbsA, respectively. Within each plot each point represents the accuracy obtained in a partition for the models represented in the vertical and horizontal axis. Points above (below) the 45&#xB0; line indicate higher (lower) accuracy of the model in the vertical axis, relative to the one in the horizontal axis. We observed that OLS always fitted the data better than GibbsI and GibbsA in the training data sets; however, GibbsI and GibbsA always outperformed OLS by a sizable margin in terms of prediction accuracy in testing data sets. Finally, incorporating genetic information (GibbsA) always led to higher prediction accuracy than models that assumed independence between lines (GibbsI).</p>
        <fig id="fig5" fig-type="figure" position="float">
          <label>Figure 5</label>
          <caption>
            <p>Prediction accuracy for training and validation sets for the three methods implemented in Box 8.</p>
          </caption>
          <graphic xlink:href="589f5"/>
        </fig>
        <p>We also noted in <xref ref-type="table" rid="t4">Table 4</xref> that the correlations (here we reported results only for the first replicate) for the parameter estimates among different models reduced compared to Example 1 due to the missing values. For example, the correlation for the estimated <bold>b</bold> among different models reduced to 0.85 between OLS and GibbsI, 0.64 between OLS and GibbsA, and 0.79 between GibbsI and GibbsA.</p>
        <table-wrap id="t4" position="float">
          <label>Table 4</label>
          <caption>
            <title>Pearson&#x2019;s product-moment correlation between parameter estimates derived by each of the three methods implemented in <xref ref-type="boxed-text" rid="box8">Box 8</xref> (results from the first replicate only)</title>
          </caption>
          <table frame="hsides" rules="groups">
            <col width="25%" span="1"/>
            <col width="25%" span="1"/>
            <col width="25%" span="1"/>
            <col width="25%" span="1"/>
            <thead>
              <tr>
                <th valign="top" align="left" scope="col" rowspan="1" colspan="1"/>
                <th valign="top" align="center" scope="col" rowspan="1" colspan="1">OLS&#x2013;GibbsI</th>
                <th valign="top" align="center" scope="col" rowspan="1" colspan="1">OLS&#x2013;GibbsA</th>
                <th valign="top" align="center" scope="col" rowspan="1" colspan="1">GibbsI&#x2013;GibbsA</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td valign="top" align="left" scope="row" rowspan="1" colspan="1">
                  <inline-formula>
                    <mml:math id="me96">
                      <mml:mover accent="true">
                        <mml:mi>h</mml:mi>
                        <mml:mo>^</mml:mo>
                      </mml:mover>
                    </mml:math>
                  </inline-formula>
                </td>
                <td valign="top" align="center" rowspan="1" colspan="1">1.00</td>
                <td valign="top" align="center" rowspan="1" colspan="1">1.00</td>
                <td valign="top" align="center" rowspan="1" colspan="1">1.00</td>
              </tr>
              <tr>
                <td valign="top" align="left" scope="row" rowspan="1" colspan="1">
                  <inline-formula>
                    <mml:math id="me97">
                      <mml:mover accent="true">
                        <mml:mi>b</mml:mi>
                        <mml:mo>^</mml:mo>
                      </mml:mover>
                    </mml:math>
                  </inline-formula>
                </td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.85</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.64</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.79</td>
              </tr>
              <tr>
                <td valign="top" align="left" scope="row" rowspan="1" colspan="1">
                  <inline-formula>
                    <mml:math id="me98">
                      <mml:mover accent="true">
                        <mml:mi>g</mml:mi>
                        <mml:mo>^</mml:mo>
                      </mml:mover>
                    </mml:math>
                  </inline-formula>
                </td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.96</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.73</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.77</td>
              </tr>
              <tr>
                <td valign="top" align="left" scope="row" rowspan="1" colspan="1">
                  <inline-formula>
                    <mml:math id="me99">
                      <mml:mover accent="true">
                        <mml:mi>y</mml:mi>
                        <mml:mo>^</mml:mo>
                      </mml:mover>
                    </mml:math>
                  </inline-formula>
                </td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.91</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.87</td>
                <td valign="top" align="center" rowspan="1" colspan="1">0.97</td>
              </tr>
            </tbody>
          </table>
        </table-wrap>
      </sec>
    </sec>
    <sec id="s14">
      <title>Computation Time for 599 Wheat Lines</title>
      <p>We ran the FW function in an Intel Core i7 1867 MHz Processor (R was executed in a single thread) with 16 GB of RAM memories. We recorded the memory and time usage for Gibbs methods with 50000 iterations. With the full data set (599 varieties, 2396 observations) the process used approximately 50 M of RAM memory for GibbsA, 17 M of RAM for GibbsI, and 153 M for OLS. The time needed to finish the process was: 11 min for GibbsA, 3 min for GibbsI, and 2 sec for OLS.</p>
    </sec>
    <sec id="s15">
      <title>Concluding Remarks</title>
      <p>The FW package allows fitting Finlay&#x2013;Wilkinson regression with ordinary least square method and Bayesian method. For Bayesian method, covariance matrix among varieties and environments can be included in the model. The interface allows the user to fit the models (<italic>e.g.</italic>, OLS <italic>vs.</italic> Gibbs) and visualize the results easily. The algorithms for Gibbs sampler are implemented in C and the speed is high. The package also provided flexibility for changing the hyper-parameters and model output.</p>
      <p>For incomplete/unbalanced experimental design the Bayesian approach is expected to have better statistical performance and prediction accuracy than the traditional two-step OLS method. Furthermore, the Bayesian models implemented in FW allows incorporating pedigree and marker information as well as modeling environment covariance. A cross-validation study based on real wheat data confirmed those expectations; indeed, the Bayesian method incorporating relationships between lines had a prediction accuracy that was 30% greater than the two-step OLS method.</p>
    </sec>
    <sec sec-type="supplementary-material">
      <title>Supplementary Material</title>
      <supplementary-material id="PMC_1" content-type="local-data">
        <caption>
          <title>Supporting Information</title>
        </caption>
        <media mimetype="text" mime-subtype="html" xlink:href="supp_6_3_589__index.html"/>
        <media xlink:role="associated-file" mimetype="application" mime-subtype="pdf" xlink:href="supp_g3.115.026328_FileS1.pdf"/>
        <media xlink:role="associated-file" mimetype="application" mime-subtype="pdf" xlink:href="supp_g3.115.026328_FileS2.pdf"/>
      </supplementary-material>
    </sec>
  </body>
  <back>
    <ack>
      <title>Acknowledgments</title>
      <p>We thank the collaborators in national agricultural research institutes who carried out the Elite Spring Wheat Yield Trials (ESWYT) and provided the phenotypic data analyzed in this article. G.d.l.C. and L.L. received financial support from NIH grants R01GM101219 and R01GM099992 and from Arvalis. G.d.l.C. received financial support from Arvalis and CIMMYT.</p>
    </ack>
    <fn-group>
      <fn id="fn1" fn-type="supplementary-material">
        <p>Supporting information is available online at <ext-link ext-link-type="uri" xlink:href="http://www.g3journal.org/lookup/suppl/doi:10.1534/g3.115.026328/-/DC1">www.g3journal.org/lookup/suppl/doi:10.1534/g3.115.026328/-/DC1</ext-link></p>
      </fn>
      <fn id="fn2">
        <p>Communicating editor: D. J. de Koning</p>
      </fn>
    </fn-group>
    <ref-list>
      <title>Literature Cited</title>
      <ref id="bib1">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Casella</surname><given-names>G.</given-names></name><name><surname>George</surname><given-names>E. I.</given-names></name></person-group>, <year>1992</year>&#x2003;<article-title>Explaining the Gibbs sampler.</article-title><source>Am. Stat.</source><volume>46</volume>: <fpage>167</fpage>&#x2013;<lpage>174</lpage>.</mixed-citation>
      </ref>
      <ref id="bib2">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Copas</surname><given-names>J. B.</given-names></name></person-group>, <year>1983</year>&#x2003;<article-title>Regression, prediction and shrinkage.</article-title><source>J. R. Stat. Soc., B</source><volume>45</volume>: <fpage>311</fpage>&#x2013;<lpage>354</lpage>.</mixed-citation>
      </ref>
      <ref id="bib3">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Crossa</surname><given-names>J.</given-names></name><name><surname>de Los Campos</surname><given-names>G.</given-names></name><name><surname>P&#xE9;rez</surname><given-names>P.</given-names></name><name><surname>Gianola</surname><given-names>D.</given-names></name><name><surname>Burgue&#xF1;o</surname><given-names>J.</given-names></name><etal/></person-group>, <year>2010</year>&#x2003;<article-title>Prediction of genetic values of quantitative traits in plant breeding using pedigree and molecular markers.</article-title><source>Genetics</source><volume>186</volume>: <fpage>713</fpage>&#x2013;<lpage>724</lpage>.<pub-id pub-id-type="pmid">20813882</pub-id></mixed-citation>
      </ref>
      <ref id="bib4">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Finlay</surname><given-names>K.</given-names></name><name><surname>Wilkinson</surname><given-names>G.</given-names></name></person-group>, <year>1963</year>&#x2003;<article-title>The analysis of adaptation in a plant-breeding programme.</article-title><source>Crop Pasture Sci.</source><volume>14</volume>: <fpage>742</fpage>&#x2013;<lpage>754</lpage>.</mixed-citation>
      </ref>
      <ref id="bib5">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Frank</surname><given-names>L. E.</given-names></name><name><surname>Friedman</surname><given-names>J. H.</given-names></name></person-group>, <year>1993</year>&#x2003;<article-title>A statistical view of some chemometrics regression tools.</article-title><source>Technometrics</source><volume>35</volume>: <fpage>109</fpage>&#x2013;<lpage>135</lpage>.</mixed-citation>
      </ref>
      <ref id="bib6">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Geman</surname><given-names>S.</given-names></name><name><surname>Geman</surname><given-names>D.</given-names></name></person-group>, <year>1984</year>&#x2003;<article-title>Stochastic relaxation, Gibbs distributions, and the bayesian restoration of images.</article-title><source>IEEE Trans. Pattern Anal. Mach. Intell.</source><volume>6</volume>: <fpage>721</fpage>&#x2013;<lpage>741</lpage>.<pub-id pub-id-type="pmid">22499653</pub-id></mixed-citation>
      </ref>
      <ref id="bib7">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gregorius</surname><given-names>H.-R.</given-names></name><name><surname>Namkoong</surname><given-names>G.</given-names></name></person-group>, <year>1986</year>&#x2003;<article-title>Joint analysis of genotypic and environmental effects.</article-title><source>Theor. Appl. Genet.</source><volume>72</volume>: <fpage>413</fpage>&#x2013;<lpage>422</lpage>.<pub-id pub-id-type="pmid">24247951</pub-id></mixed-citation>
      </ref>
      <ref id="bib8">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jarqu&#xED;n</surname><given-names>D.</given-names></name><name><surname>Crossa</surname><given-names>J.</given-names></name><name><surname>Lacaze</surname><given-names>X.</given-names></name><name><surname>Du Cheyron</surname><given-names>P.</given-names></name><name><surname>Daucourt</surname><given-names>J.</given-names></name><etal/></person-group>, <year>2014</year>&#x2003;<article-title>A reaction norm model for genomic selection using high-dimensional genomic and environmental data.</article-title><source>Theor. Appl. Genet.</source><volume>127</volume>: <fpage>595</fpage>&#x2013;<lpage>607</lpage>.<pub-id pub-id-type="pmid">24337101</pub-id></mixed-citation>
      </ref>
      <ref id="bib9">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>P&#xE9;rez</surname><given-names>P.</given-names></name><name><surname>de Los Campos</surname><given-names>G.</given-names></name><name><surname>Crossa</surname><given-names>J.</given-names></name><name><surname>Gianola</surname><given-names>D.</given-names></name></person-group>, <year>2010</year>&#x2003;<article-title>Genomic-enabled prediction based on molecular markers and pedigree using the bayesian linear regression package in R.</article-title><source>Plant Genome</source><volume>3</volume>: <fpage>106</fpage>&#x2013;<lpage>116</lpage>.<pub-id pub-id-type="pmid">21566722</pub-id></mixed-citation>
      </ref>
      <ref id="bib10">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Perkins</surname><given-names>J. M.</given-names></name><name><surname>Jinks</surname><given-names>J.</given-names></name></person-group>, <year>1968</year>&#x2003;<article-title>Environmental and genotype-environmental components of variability III. Multiple lines and crosses.</article-title><source>Heredity</source><volume>23</volume>: <fpage>339</fpage>&#x2013;<lpage>356</lpage>.<pub-id pub-id-type="pmid">5250121</pub-id></mixed-citation>
      </ref>
      <ref id="bib11">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Plummer</surname><given-names>M.</given-names></name><name><surname>Best</surname><given-names>N.</given-names></name><name><surname>Cowles</surname><given-names>K.</given-names></name><name><surname>Vines</surname><given-names>K.</given-names></name></person-group>, <year>2006</year>&#x2003;<article-title>CODA: convergence diagnosis and output analysis for MCMC.</article-title><source>R News</source><volume>6</volume>: <fpage>7</fpage>&#x2013;<lpage>11</lpage>.</mixed-citation>
      </ref>
      <ref id="bib12">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><collab>R Development Core Team</collab></person-group>, <year>2011</year>&#x2003;<source>R: A Language and Environment for Statistical Computing</source>. <publisher-name>R Foundation for Statistical Computing</publisher-name>, <publisher-loc>Vienna, Austria</publisher-loc>.</mixed-citation>
      </ref>
      <ref id="bib13">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shariati</surname><given-names>M.</given-names></name><name><surname>Korsgaard</surname><given-names>I.</given-names></name><name><surname>Sorensen</surname><given-names>D.</given-names></name></person-group>, <year>2009</year>&#x2003;<article-title>Identifiability of parameters and behaviour of mcmc chains: a case study using the reaction norm model.</article-title><source>J. Anim. Breed. Genet.</source><volume>126</volume>: <fpage>92</fpage>&#x2013;<lpage>102</lpage>.<pub-id pub-id-type="pmid">19320765</pub-id></mixed-citation>
      </ref>
      <ref id="bib14">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Su</surname><given-names>G.</given-names></name><name><surname>Madsen</surname><given-names>P.</given-names></name><name><surname>Lund</surname><given-names>M. S.</given-names></name><name><surname>Sorensen</surname><given-names>D.</given-names></name><name><surname>Korsgaard</surname><given-names>I. R.</given-names></name><etal/></person-group>, <year>2006</year>&#x2003;<article-title>Bayesian analysis of the linear reaction norm model with unknown covariates.</article-title><source>J. Anim. Sci.</source><volume>84</volume>: <fpage>1651</fpage>&#x2013;<lpage>1657</lpage>.<pub-id pub-id-type="pmid">16775048</pub-id></mixed-citation>
      </ref>
      <ref id="bib15">
        <mixed-citation publication-type="webpage">Walsh, J. B., and M. Lynch, 2014&#x2003;Selection and G &#xD7; E: advanced topics, Chapter 44 in Evolution and Selection of Quantitative Traits: II. Advanced Topics in Breeding and Evolution. Available at: <ext-link ext-link-type="uri" xlink:href="http://nitro.biosci.arizona.edu/zbook/NewVolume_2/pdf/Chapter44.pdf">http://nitro.biosci.arizona.edu/zbook/NewVolume_2/pdf/Chapter44.pdf</ext-link>. Accessed December 5, 2015.</mixed-citation>
      </ref>
    </ref-list>
  </back>
</article>
